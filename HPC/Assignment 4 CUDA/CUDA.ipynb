{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4utsP1M_7y5X",
        "outputId": "b1220c9a-e97f-4dda-c254-5c5e84ad8f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ggVprrt8m-f",
        "outputId": "a81f0b33-6ad0-4460-8104-e2b7244c4321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-ie757v4c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-ie757v4c\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=f6e677e8f27f35205024e7c99c6fd3773a6a00af9eca403a82619f52cf2ffddd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l352jtwh/wheels/db/c1/1f/a2bb07bbb4a1ce3c43921252aeafaa6205f08637e292496f04\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPq7Qyhg9HwO",
        "outputId": "49c63d9e-d72e-4910-959e-a92fd9bdefa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "//vector addition CUDA  1\n",
        "#include<iostream>\n",
        "#include<time.h>\n",
        "#define SIZE 100000\n",
        "using namespace std;\n",
        "\n",
        "__global__ void addVect(int *vect1 ,int *vect2 , int *resultVect){\n",
        "    int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    resultVect[i] = vect1[i] + vect2[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int *d_inVect1,*d_inVect2,*d_outResultVector;   //data storage for gpu\n",
        "    int vect1[SIZE],vect2[SIZE],resultVect[SIZE];   // data storage for cpu\n",
        "    cudaEvent_t gpu_start,gpu_stop;\n",
        "    float gpu_elapsed_time;\n",
        "\n",
        "    // Initializing both the vectors\n",
        "    for(int i = 0 ; i < SIZE ; i++){\n",
        "        vect1[i] = i;\n",
        "        vect2[i] = i;\n",
        "    }\n",
        "    // Parallel code\n",
        "\n",
        "    // Allocate memory on GPU for 3 vectors\n",
        "    cudaMalloc((void**)&d_inVect1,SIZE*(sizeof(int)));\n",
        "    cudaMalloc((void**)&d_inVect2,SIZE*(sizeof(int)));\n",
        "    cudaMalloc((void**)&d_outResultVector,SIZE*(sizeof(int)));\n",
        "\n",
        "    // COPY the vector contents\n",
        "    cudaMemcpy(d_inVect1,vect1,SIZE*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_inVect2,vect2,SIZE*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Start record for gpu_start\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start,0);\n",
        "\n",
        "    //blk is number of blocks with each block of 1024 threads\n",
        "    int blk = SIZE/1024;\n",
        "    // Call the kernel\n",
        "    addVect<<<blk+1,1024>>>(d_iVnect1,d_inVect2,d_outResultVector);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaEventRecord(gpu_stop,0);\n",
        "    // Copy gpu mem to cpu mem\n",
        "    cudaMemcpy(resultVect,d_outResultVector,SIZE*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    //cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time,gpu_start,gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cout<<\"The time taken by GPU is :\"<<gpu_elapsed_time<<endl;\n",
        "    \n",
        "    // verify that the GPU did the work we requested\n",
        "    bool success = true;\n",
        "    int total=0;\n",
        "    cout<<\"\\n Checking \"<<SIZE<<\" values in the array.......\\n\";\n",
        "    for (int i=0; i<SIZE; i++) {\n",
        "        if ((vect1[i] + vect2[i]) != resultVect[i]) {\n",
        "            printf( \"Error:  %d + %d != %d\\n\", vect1[i], vect2[i], resultVect[i] );\n",
        "            success = false;\n",
        "        }\n",
        "        total += 1;\n",
        "    }\n",
        "    if (success)  cout<<\"We did it \"<<total<<\"  values correct!\\n\";\n",
        "\n",
        "    // Sequential code of vector addition with time measurement\n",
        "    clock_t startTime = clock();\n",
        "    int resultVect2[SIZE];\n",
        "    for(int i = 0 ; i < SIZE ; i++){\n",
        "        resultVect2[i] = vect1[i] + vect2[i];\n",
        "    }\n",
        "    clock_t endTime = clock();\n",
        "     cout<<\"\\nTime for sequential: \"<<((float)(endTime-startTime)/CLOCKS_PER_SEC)*1000;\n",
        "     cout<<\"\\nAll results are correct!!!, \\n Speedup = \"<<((float)(endTime-startTime)/CLOCKS_PER_SEC)*1000 / gpu_elapsed_time<<\"\\n\";\n",
        "     // free the memory we allocated on the GPU\n",
        "     cudaFree(d_inVect1);\n",
        "     cudaFree(d_inVect2);\n",
        "     cudaFree(d_outResultVector);\n",
        "  \n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH8rz1S072Op",
        "outputId": "c3e6f059-a692-4433-feea-0a720d8a9c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time taken by GPU is :0.05376\n",
            "\n",
            " Checking 100000 values in the array.......\n",
            "We did it 100000  values correct!\n",
            "\n",
            "Time for sequential: 0.259\n",
            "All results are correct!!!, \n",
            " Speedup = 4.81771\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <iostream>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "// Define matrix size\n",
        "#define N 16\n",
        "\n",
        "__global__ void matrix_multiply(float *a, float *b, float *c) {\n",
        "    // Calculate thread index\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Calculate the product of two matrices\n",
        "    float sum = 0;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sum += a[row * N + i] * b[i * N + col];\n",
        "    }\n",
        "    c[row * N + col] = sum;\n",
        "}\n",
        "\n",
        "void matrixMultiplication(float *a ,float *b ,float *c) {\n",
        " \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            float sum = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                sum += a[i * N+ k] * b[k * N + j];\n",
        "            }\n",
        "            c[i * N + j] = sum;\n",
        "        }\n",
        "    }\n",
        "       // Print the result matrix\n",
        "          printf(\"\\nMatrix result using normal function : \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", c[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n-----------------------------------------------------------------------\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    float *a, *b, *c,*d;  // Pointers to matrices in host memory\n",
        "    float *dev_a, *dev_b, *dev_c;  // Pointers to matrices in device memory\n",
        "    int size = N * N * sizeof(float);\n",
        "\n",
        "    // Allocate memory for matrices in host memory\n",
        "    a = (float *)malloc(size);\n",
        "    b = (float *)malloc(size);\n",
        "    c = (float *)malloc(size);\n",
        "    d = (float *)malloc(size);\n",
        "\n",
        "    // Initialize matrices with random values\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        a[i] = rand() % 100;\n",
        "        b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for matrices in device memory\n",
        "    cudaMalloc((void **)&dev_a, size);\n",
        "    cudaMalloc((void **)&dev_b, size);\n",
        "    cudaMalloc((void **)&dev_c, size);\n",
        "\n",
        "    // Copy matrices from host memory to device memory\n",
        "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define the grid and block dimensions\n",
        "    dim3 dimGrid(N / 16, N / 16);\n",
        "    dim3 dimBlock(16, 16);\n",
        "\n",
        "    // Call the kernel function\n",
        "\n",
        "    clock_t tic, toc;\n",
        "tic = clock();\n",
        "   matrix_multiply<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "    toc = clock();\n",
        "\n",
        "    float timeTakenGPU = ((float)(toc - tic)) / CLOCKS_PER_SEC;\n",
        "\n",
        "    // Copy the result matrix from device memory to host memory\n",
        "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "       // Print the A matrix\n",
        "       printf(\"Matrix A : \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", a[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n---------------------------------------------------------------------------------\\n\");\n",
        "\n",
        "       // Print the B matrix\n",
        "       printf(\"Matrix B : \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", b[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "      printf(\"\\n---------------------------------------------------------------------------------\");\n",
        "\n",
        "    // normal \n",
        "     // CPU\n",
        "   \n",
        "\n",
        "    tic = clock();\n",
        "    matrixMultiplication(a,b,d);\n",
        "    toc = clock();\n",
        "\n",
        "  float timeTakenCPU =(float) ((toc - tic)) / CLOCKS_PER_SEC;\n",
        "    \n",
        "\n",
        "    // Print the result matrix parallel\n",
        "       printf(\"\\nMatrix Result using cuda : \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", c[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"----------------------------------------------------------------------------------\\n\");\n",
        "\n",
        "    // Free memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    printf(\"\\n \");\n",
        "   printf(\"CPU Time: %f \\n\", timeTakenCPU);\n",
        "   printf(\"GPU Time: %f \\n\", timeTakenGPU);\n",
        "   printf(\"Speed Up: %f \\n\", timeTakenCPU/timeTakenGPU);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "-Uc33nB08iTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5f2613-9927-4350-8b76-29ca0a792c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A : \n",
            "83.000000 77.000000 93.000000 86.000000 49.000000 62.000000 90.000000 63.000000 40.000000 72.000000 11.000000 67.000000 82.000000 62.000000 67.000000 29.000000 \n",
            "22.000000 69.000000 93.000000 11.000000 29.000000 21.000000 84.000000 98.000000 15.000000 13.000000 91.000000 56.000000 62.000000 96.000000 5.000000 84.000000 \n",
            "36.000000 46.000000 13.000000 24.000000 82.000000 14.000000 34.000000 43.000000 87.000000 76.000000 88.000000 3.000000 54.000000 32.000000 76.000000 39.000000 \n",
            "26.000000 94.000000 95.000000 34.000000 67.000000 97.000000 17.000000 52.000000 1.000000 86.000000 65.000000 44.000000 40.000000 31.000000 97.000000 81.000000 \n",
            "9.000000 67.000000 97.000000 86.000000 6.000000 19.000000 28.000000 32.000000 3.000000 70.000000 8.000000 40.000000 96.000000 18.000000 46.000000 21.000000 \n",
            "79.000000 64.000000 41.000000 93.000000 34.000000 24.000000 87.000000 43.000000 27.000000 59.000000 32.000000 37.000000 75.000000 74.000000 58.000000 29.000000 \n",
            "35.000000 18.000000 43.000000 28.000000 76.000000 43.000000 13.000000 6.000000 4.000000 28.000000 69.000000 17.000000 24.000000 70.000000 90.000000 72.000000 \n",
            "44.000000 5.000000 54.000000 69.000000 42.000000 97.000000 55.000000 48.000000 22.000000 99.000000 46.000000 40.000000 11.000000 5.000000 61.000000 78.000000 \n",
            "20.000000 44.000000 22.000000 8.000000 82.000000 24.000000 62.000000 0.000000 52.000000 79.000000 68.000000 73.000000 81.000000 33.000000 60.000000 99.000000 \n",
            "99.000000 59.000000 13.000000 90.000000 26.000000 84.000000 90.000000 76.000000 36.000000 45.000000 79.000000 87.000000 48.000000 59.000000 36.000000 42.000000 \n",
            "6.000000 13.000000 21.000000 19.000000 21.000000 39.000000 40.000000 5.000000 27.000000 84.000000 20.000000 22.000000 96.000000 30.000000 92.000000 72.000000 \n",
            "25.000000 22.000000 40.000000 98.000000 98.000000 24.000000 9.000000 19.000000 32.000000 94.000000 79.000000 73.000000 50.000000 60.000000 79.000000 93.000000 \n",
            "21.000000 4.000000 61.000000 26.000000 44.000000 2.000000 84.000000 42.000000 28.000000 72.000000 58.000000 36.000000 53.000000 3.000000 33.000000 90.000000 \n",
            "67.000000 68.000000 0.000000 88.000000 49.000000 3.000000 63.000000 53.000000 86.000000 52.000000 75.000000 57.000000 36.000000 14.000000 60.000000 28.000000 \n",
            "50.000000 56.000000 94.000000 99.000000 39.000000 28.000000 0.000000 47.000000 59.000000 35.000000 39.000000 15.000000 4.000000 49.000000 85.000000 43.000000 \n",
            "77.000000 38.000000 49.000000 67.000000 92.000000 43.000000 29.000000 82.000000 41.000000 26.000000 61.000000 60.000000 23.000000 81.000000 90.000000 96.000000 \n",
            "\n",
            "---------------------------------------------------------------------------------\n",
            "Matrix B : \n",
            "86.000000 15.000000 35.000000 92.000000 21.000000 27.000000 59.000000 26.000000 26.000000 36.000000 68.000000 29.000000 30.000000 23.000000 35.000000 2.000000 \n",
            "58.000000 67.000000 56.000000 42.000000 73.000000 19.000000 37.000000 24.000000 70.000000 26.000000 80.000000 73.000000 70.000000 81.000000 25.000000 27.000000 \n",
            "5.000000 29.000000 57.000000 95.000000 45.000000 67.000000 64.000000 50.000000 8.000000 78.000000 84.000000 51.000000 99.000000 60.000000 68.000000 12.000000 \n",
            "86.000000 39.000000 70.000000 78.000000 1.000000 2.000000 92.000000 56.000000 80.000000 41.000000 89.000000 19.000000 29.000000 17.000000 71.000000 75.000000 \n",
            "27.000000 56.000000 53.000000 65.000000 83.000000 24.000000 71.000000 29.000000 19.000000 68.000000 15.000000 49.000000 23.000000 45.000000 51.000000 55.000000 \n",
            "88.000000 28.000000 50.000000 0.000000 64.000000 14.000000 56.000000 91.000000 65.000000 36.000000 51.000000 28.000000 7.000000 21.000000 95.000000 37.000000 \n",
            "93.000000 28.000000 11.000000 29.000000 4.000000 63.000000 38.000000 40.000000 18.000000 88.000000 17.000000 96.000000 43.000000 83.000000 99.000000 25.000000 \n",
            "90.000000 39.000000 86.000000 82.000000 64.000000 7.000000 4.000000 11.000000 28.000000 43.000000 68.000000 22.000000 10.000000 1.000000 30.000000 5.000000 \n",
            "36.000000 26.000000 65.000000 16.000000 58.000000 37.000000 24.000000 36.000000 99.000000 50.000000 71.000000 31.000000 30.000000 94.000000 63.000000 81.000000 \n",
            "96.000000 73.000000 68.000000 95.000000 66.000000 40.000000 84.000000 42.000000 7.000000 56.000000 18.000000 12.000000 72.000000 9.000000 10.000000 87.000000 \n",
            "1.000000 72.000000 55.000000 99.000000 4.000000 11.000000 67.000000 28.000000 50.000000 58.000000 24.000000 69.000000 81.000000 84.000000 72.000000 50.000000 \n",
            "85.000000 99.000000 42.000000 13.000000 90.000000 90.000000 81.000000 36.000000 55.000000 4.000000 69.000000 76.000000 55.000000 42.000000 84.000000 5.000000 \n",
            "67.000000 13.000000 54.000000 59.000000 2.000000 6.000000 21.000000 68.000000 89.000000 8.000000 98.000000 8.000000 48.000000 33.000000 48.000000 54.000000 \n",
            "46.000000 29.000000 46.000000 97.000000 90.000000 33.000000 97.000000 92.000000 25.000000 96.000000 88.000000 29.000000 60.000000 21.000000 4.000000 27.000000 \n",
            "48.000000 2.000000 97.000000 43.000000 2.000000 3.000000 81.000000 38.000000 51.000000 34.000000 92.000000 27.000000 29.000000 64.000000 29.000000 35.000000 \n",
            "0.000000 71.000000 89.000000 88.000000 95.000000 44.000000 90.000000 40.000000 69.000000 32.000000 42.000000 17.000000 61.000000 9.000000 25.000000 67.000000 \n",
            "\n",
            "---------------------------------------------------------------------------------\n",
            "Matrix result using normal function : \n",
            "65904.000000 40690.000000 57918.000000 63099.000000 45841.000000 32788.000000 61178.000000 46998.000000 46482.000000 48715.000000 66878.000000 41279.000000 47970.000000 42931.000000 52961.000000 38144.000000 \n",
            "42017.000000 39464.000000 47585.000000 58761.000000 43940.000000 29493.000000 48298.000000 36932.000000 36373.000000 44175.000000 51264.000000 38855.000000 46264.000000 37339.000000 42266.000000 27729.000000 \n",
            "37880.000000 31542.000000 46395.000000 48546.000000 32842.000000 18193.000000 43451.000000 29479.000000 36347.000000 36469.000000 41404.000000 28125.000000 34629.000000 36640.000000 33894.000000 36490.000000 \n",
            "48552.000000 42445.000000 58569.000000 58988.000000 47595.000000 26592.000000 59424.000000 41158.000000 41318.000000 41962.000000 55260.000000 35989.000000 46663.000000 38089.000000 44190.000000 37091.000000 \n",
            "39563.000000 26768.000000 39362.000000 42637.000000 25730.000000 19416.000000 38918.000000 30367.000000 31505.000000 27516.000000 46016.000000 23365.000000 35133.000000 25884.000000 31899.000000 26954.000000 \n",
            "54726.000000 33250.000000 47595.000000 55699.000000 34326.000000 24599.000000 52251.000000 38921.000000 39483.000000 41462.000000 55066.000000 33827.000000 39903.000000 35653.000000 41679.000000 33627.000000 \n",
            "27756.000000 26561.000000 39808.000000 44242.000000 30762.000000 16960.000000 45893.000000 29999.000000 27816.000000 32462.000000 37319.000000 23751.000000 31061.000000 26535.000000 28785.000000 26753.000000 \n",
            "47020.000000 34751.000000 47592.000000 48483.000000 36372.000000 23932.000000 51124.000000 34925.000000 33851.000000 36617.000000 41459.000000 28106.000000 34576.000000 27947.000000 41793.000000 34545.000000 \n",
            "40716.000000 39599.000000 47287.000000 48820.000000 40949.000000 27589.000000 51499.000000 34672.000000 39691.000000 36088.000000 43251.000000 33416.000000 41228.000000 37294.000000 39793.000000 37888.000000 \n",
            "63793.000000 42528.000000 52849.000000 57975.000000 42491.000000 28869.000000 57821.000000 42784.000000 46805.000000 43648.000000 58163.000000 40989.000000 41767.000000 39430.000000 53058.000000 35340.000000 \n",
            "34332.000000 23760.000000 38785.000000 37054.000000 25844.000000 17028.000000 38826.000000 29911.000000 30973.000000 25920.000000 37190.000000 18869.000000 29402.000000 24095.000000 27223.000000 30306.000000 \n",
            "45721.000000 43744.000000 56657.000000 61420.000000 44390.000000 26349.000000 64094.000000 39843.000000 42653.000000 41307.000000 51932.000000 31962.000000 44197.000000 34462.000000 41874.000000 43473.000000 \n",
            "33846.000000 30832.000000 38853.000000 44918.000000 29148.000000 23722.000000 39978.000000 26114.000000 27889.000000 32600.000000 33666.000000 27108.000000 34634.000000 28343.000000 34286.000000 29376.000000 \n",
            "48434.000000 35709.000000 46856.000000 48250.000000 32324.000000 22142.000000 46386.000000 29667.000000 41595.000000 35409.000000 47622.000000 33865.000000 35259.000000 38915.000000 41254.000000 35039.000000 \n",
            "37679.000000 28968.000000 48215.000000 50746.000000 33415.000000 19717.000000 48447.000000 32040.000000 35513.000000 36562.000000 50916.000000 26501.000000 35654.000000 32154.000000 34693.000000 30825.000000 \n",
            "49898.000000 41041.000000 59253.000000 63583.000000 48789.000000 27362.000000 62004.000000 40471.000000 43652.000000 45587.000000 58674.000000 36026.000000 42021.000000 37276.000000 44555.000000 36523.000000 \n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "Matrix Result using cuda : \n",
            "65904.000000 40690.000000 57918.000000 63099.000000 45841.000000 32788.000000 61178.000000 46998.000000 46482.000000 48715.000000 66878.000000 41279.000000 47970.000000 42931.000000 52961.000000 38144.000000 \n",
            "42017.000000 39464.000000 47585.000000 58761.000000 43940.000000 29493.000000 48298.000000 36932.000000 36373.000000 44175.000000 51264.000000 38855.000000 46264.000000 37339.000000 42266.000000 27729.000000 \n",
            "37880.000000 31542.000000 46395.000000 48546.000000 32842.000000 18193.000000 43451.000000 29479.000000 36347.000000 36469.000000 41404.000000 28125.000000 34629.000000 36640.000000 33894.000000 36490.000000 \n",
            "48552.000000 42445.000000 58569.000000 58988.000000 47595.000000 26592.000000 59424.000000 41158.000000 41318.000000 41962.000000 55260.000000 35989.000000 46663.000000 38089.000000 44190.000000 37091.000000 \n",
            "39563.000000 26768.000000 39362.000000 42637.000000 25730.000000 19416.000000 38918.000000 30367.000000 31505.000000 27516.000000 46016.000000 23365.000000 35133.000000 25884.000000 31899.000000 26954.000000 \n",
            "54726.000000 33250.000000 47595.000000 55699.000000 34326.000000 24599.000000 52251.000000 38921.000000 39483.000000 41462.000000 55066.000000 33827.000000 39903.000000 35653.000000 41679.000000 33627.000000 \n",
            "27756.000000 26561.000000 39808.000000 44242.000000 30762.000000 16960.000000 45893.000000 29999.000000 27816.000000 32462.000000 37319.000000 23751.000000 31061.000000 26535.000000 28785.000000 26753.000000 \n",
            "47020.000000 34751.000000 47592.000000 48483.000000 36372.000000 23932.000000 51124.000000 34925.000000 33851.000000 36617.000000 41459.000000 28106.000000 34576.000000 27947.000000 41793.000000 34545.000000 \n",
            "40716.000000 39599.000000 47287.000000 48820.000000 40949.000000 27589.000000 51499.000000 34672.000000 39691.000000 36088.000000 43251.000000 33416.000000 41228.000000 37294.000000 39793.000000 37888.000000 \n",
            "63793.000000 42528.000000 52849.000000 57975.000000 42491.000000 28869.000000 57821.000000 42784.000000 46805.000000 43648.000000 58163.000000 40989.000000 41767.000000 39430.000000 53058.000000 35340.000000 \n",
            "34332.000000 23760.000000 38785.000000 37054.000000 25844.000000 17028.000000 38826.000000 29911.000000 30973.000000 25920.000000 37190.000000 18869.000000 29402.000000 24095.000000 27223.000000 30306.000000 \n",
            "45721.000000 43744.000000 56657.000000 61420.000000 44390.000000 26349.000000 64094.000000 39843.000000 42653.000000 41307.000000 51932.000000 31962.000000 44197.000000 34462.000000 41874.000000 43473.000000 \n",
            "33846.000000 30832.000000 38853.000000 44918.000000 29148.000000 23722.000000 39978.000000 26114.000000 27889.000000 32600.000000 33666.000000 27108.000000 34634.000000 28343.000000 34286.000000 29376.000000 \n",
            "48434.000000 35709.000000 46856.000000 48250.000000 32324.000000 22142.000000 46386.000000 29667.000000 41595.000000 35409.000000 47622.000000 33865.000000 35259.000000 38915.000000 41254.000000 35039.000000 \n",
            "37679.000000 28968.000000 48215.000000 50746.000000 33415.000000 19717.000000 48447.000000 32040.000000 35513.000000 36562.000000 50916.000000 26501.000000 35654.000000 32154.000000 34693.000000 30825.000000 \n",
            "49898.000000 41041.000000 59253.000000 63583.000000 48789.000000 27362.000000 62004.000000 40471.000000 43652.000000 45587.000000 58674.000000 36026.000000 42021.000000 37276.000000 44555.000000 36523.000000 \n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            " CPU Time: 0.000153 \n",
            "GPU Time: 0.000019 \n",
            "Speed Up: 8.052632 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !nvidia-smi"
      ],
      "metadata": {
        "id": "X7WmBMQeCyH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623f44d0-b987-4137-ad1c-a1671abcd047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 18 09:11:03 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n"
      ],
      "metadata": {
        "id": "Qta_G9iFobdc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}